[
  {
    "name": "尤信程",
    "email": "scyou@ntut.edu.tw",
    "latestUpdate": "2021-12-28 11:08:03",
    "objective": "This course covers a broad classes of machine learning algorithms. After taking this course, students should be able to conduct research in this field. The emphasis of this course is not in the theoretical development (math), but in the understanding level. Therefore, many examples will be given in the lecture to show how to apply the equations to real problems. The detailed contents are given in the course schedule field.",
    "schedule": "Week 1: Class announcement and introduction to machine learning\nWeek 2: Holiday &amp; introduction to machine learning\nWeek 3: Basics of supervised learning (classification and regression), VC dimension, Bayesian decision theory, and Naive Bayes classifiers \nWeek 4: ML and MAP estimation, Sample mean and sample covariance, multivariate Gaussian,  Bias vs variance dilemma, Dimension reduction techniques: PCA, FA\nWeek 5: Dimension reduction techniques: LDA and ICA, Unsupervised learning: Clustering algorithm (k-means)\nWeek 6: Decision trees: ID3, C4.5, and bagging algorithm (random forest)\nWeek 7: Holiday\nWeek 8: Basics of optimization\nWeek 9: MT\nWeek 10: MT sol. Gradient search and linear discrimination\nWeek 11: Feedforward neural networks with examples: multi-layer perceptrons, Back propagation, and Regularization methods\nWeek 12: Deep learning and convolutional neural networks\nWeek 13, 14: More on deep neural networks: YOLO, Autoencoder, LSTM, and advanced topics, such as Bayesian networks, confidence of classification, and self-supervised learning (if time permitted)\nWeek 15: SVM \nWeek 16: Adaboost and Ensemble learning\nWeek 17: Design and analysis of experiments \nWeek 18: Final exam",
    "scorePolicy": "MT 30 %\nFinal 40 %\nHW 30 %\nProject 10 % (optional)",
    "materials": "Reference text book: Introduction to machine learning. E. Alpaydin. 2nd ed or 3rd ed. Note: textbook is only used to follow the presentation order. Much of the detailed lecture materials are NOT covered in the textbook.",
    "foreignLanguageTextbooks": false,
    "remarks": "<div style=\"background:transparent;color: blue;font-size:12pt\">Prerequisite: Calculus (partial derivatives), undergrad linear algebra (eigenvalues &amp; eigenvectors), undergrad probability (random variable, joint density, Gaussian distribution), and programming skills (Python)</div>"
  }
]
