[{"name":"吳昭正","email":"ccwu@ntut.edu.tw","latestUpdate":"2012-02-22 14:32:11","objective":"本課程將先從隨機變數的內容開始並主要介紹消息理論的基礎與應用。本課程的將涵蓋下列內容：\n(1) 熵值，相對性熵值與互訊息\n(2) 漸近等分理論\n(3) 隨機程序的熵速率\n(4) 資料壓縮\n(5) 消息理論與賭博\n(6) 頻道容量\n(7) 差別熵值\n(8) 高斯通道","schedule":"Week 1(2/22). Introduction\nWeek 2(2/29). Review of probability theory\nWeek 3(3/7). Entropy (I)\nWeek 4(3/14). Entropy (II)\nWeek 5(3/21). Mutual information\nWeek 6(3/28). Data compression\nWeek 7(4/4). Holiday\nWeek 8(4/11). Huffman coding\nWeek 9(4/18). Midterm\nWeek 10(4/25). Asymptotic equipartition property\nWeek 11(5/2). Channel capacity (I)\nWeek 12(5/9). Channel capacity (II)\nWeek 13(5/16). Universal source coding (I)\nWeek 14(5/23). Universal source coding (II)\nWeek 15(5/30). Differential entropy\nWeek 16(6/6). Gaussian Channel\nWeek 17(6/13). Term project presentation\nWeek 18(6/20). Final term","scorePolicy":"Midterm 30%\nFinal term 40%\nTerm Project 30%","materials":"Required text: \n1. Elements of Information Theory, 2nd Edition, Thomas M. Cover and Joy A. Thomas, Wiley, 2006.\nOptional text: \n1. The Mathematical Theory of Information, Jan Kåhre, The Springer, 2002.\n2. Information Theory, Inteference, and Learning Algorithms, David J. C. Mackay, Cambridge, 2003.\n3. Information Theory: Coding Theorems for Discrete Memoryless Systems, 2md Edition, Imre Csiszár and János Körner, Cambridge, 2011","foreignLanguageTextbooks":false}]
